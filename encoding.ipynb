{"cells":[{"cell_type":"code","execution_count":1,"id":"a41852c6","metadata":{"scrolled":false},"outputs":[{"name":"stderr","output_type":"stream","text":["24/12/10 03:16:34 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n","                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["+-------------------+-----------------+------+----+---------+--------+--------+------------------+-------------+-----------+---------+-----------------+----+-------+-----+----------+---------+--------+\n","|         FlightDate|          Airline|Origin|Dest|Cancelled|Diverted|DepDel15|ArrivalDelayGroups|DistanceGroup|OriginState|DestState|Operating_Airline|Year|Quarter|Month|DayofMonth|DayOfWeek|Distance|\n","+-------------------+-----------------+------+----+---------+--------+--------+------------------+-------------+-----------+---------+-----------------+----+-------+-----+----------+---------+--------+\n","|2018-01-23 00:00:00|Endeavor Air Inc.|   ABY| ATL|        0|       0|       0|                -1|            1|         GA|       GA|               9E|2018|      1|    1|        23|        2|     145|\n","|2018-01-24 00:00:00|Endeavor Air Inc.|   ABY| ATL|        0|       0|       0|                -1|            1|         GA|       GA|               9E|2018|      1|    1|        24|        3|     145|\n","|2018-01-25 00:00:00|Endeavor Air Inc.|   ABY| ATL|        0|       0|       0|                -1|            1|         GA|       GA|               9E|2018|      1|    1|        25|        4|     145|\n","|2018-01-26 00:00:00|Endeavor Air Inc.|   ABY| ATL|        0|       0|       0|                -1|            1|         GA|       GA|               9E|2018|      1|    1|        26|        5|     145|\n","|2018-01-27 00:00:00|Endeavor Air Inc.|   ABY| ATL|        0|       0|       0|                -1|            1|         GA|       GA|               9E|2018|      1|    1|        27|        6|     145|\n","+-------------------+-----------------+------+----+---------+--------+--------+------------------+-------------+-----------+---------+-----------------+----+-------+-----+----------+---------+--------+\n","only showing top 5 rows\n","\n"]}],"source":["from pyspark.sql import SparkSession\n","\n","# Initialize Spark session\n","spark = SparkSession.builder.appName(\"Flight Status Prediction\").getOrCreate()\n","\n","# Load the previously saved dataset\n","intermediate_path = \"gs://flight-analysis-ms-bucket/trusted/handled_missing_values.parquet\"\n","flight_data = spark.read.parquet(intermediate_path)\n","\n","# Verify data loaded\n","flight_data.show(5)\n"]},{"cell_type":"code","execution_count":2,"id":"8f701f5c","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["\r","[Stage 2:>                                                          (0 + 1) / 1]\r"]},{"name":"stdout","output_type":"stream","text":["+--------+------------------+\n","|Distance|numerical_features|\n","+--------+------------------+\n","|145     |[145.0]           |\n","|145     |[145.0]           |\n","|145     |[145.0]           |\n","|145     |[145.0]           |\n","|145     |[145.0]           |\n","+--------+------------------+\n","only showing top 5 rows\n","\n"]},{"name":"stderr","output_type":"stream","text":["\r","                                                                                \r"]}],"source":["from pyspark.ml.feature import VectorAssembler\n","\n","# Select numerical columns to normalize\n","numerical_cols = [\"Distance\"]\n","\n","# Assemble into a single vector column\n","assembler = VectorAssembler(inputCols=numerical_cols, outputCol=\"numerical_features\")\n","flight_data = assembler.transform(flight_data)\n","\n","# Show assembled features\n","flight_data.select(\"Distance\", \"numerical_features\").show(5, truncate=False)\n"]},{"cell_type":"code","execution_count":3,"id":"aacf6903","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["+--------+----------------------+\n","|Distance|scaled_features       |\n","+--------+----------------------+\n","|145     |[0.025971411314676868]|\n","|145     |[0.025971411314676868]|\n","|145     |[0.025971411314676868]|\n","|145     |[0.025971411314676868]|\n","|145     |[0.025971411314676868]|\n","+--------+----------------------+\n","only showing top 5 rows\n","\n"]}],"source":["from pyspark.ml.feature import MinMaxScaler\n","\n","# Apply MinMaxScaler\n","scaler = MinMaxScaler(inputCol=\"numerical_features\", outputCol=\"scaled_features\")\n","scaler_model = scaler.fit(flight_data)\n","flight_data = scaler_model.transform(flight_data)\n","\n","# Show scaled features\n","flight_data.select(\"Distance\", \"scaled_features\").show(5, truncate=False)\n"]},{"cell_type":"code","execution_count":6,"id":"5169884c","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["+------------------+--------------------------+\n","|ArrivalDelayGroups|ArrivalDelayGroups_indexed|\n","+------------------+--------------------------+\n","|                -1|                       0.0|\n","|                -1|                       0.0|\n","|                -1|                       0.0|\n","|                -1|                       0.0|\n","|                -1|                       0.0|\n","+------------------+--------------------------+\n","only showing top 5 rows\n","\n"]}],"source":["from pyspark.ml.feature import StringIndexer\n","\n","# Encode ArrivalDelayGroups\n","indexer = StringIndexer(inputCol=\"ArrivalDelayGroups\", outputCol=\"ArrivalDelayGroups_indexed\")\n","flight_data = indexer.fit(flight_data).transform(flight_data)\n","\n","# Show the encoded column\n","flight_data.select(\"ArrivalDelayGroups\", \"ArrivalDelayGroups_indexed\").show(5)\n"]},{"cell_type":"code","execution_count":7,"id":"bbde6f1d","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"data":{"text/plain":["28"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["# Count unique values in categorical columns\n","flight_data.select(\"Origin\").distinct().count()\n","flight_data.select(\"Dest\").distinct().count()\n","flight_data.select(\"Airline\").distinct().count()\n"]},{"cell_type":"code","execution_count":8,"id":"1179ab7d","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["+-----------------+---------------+\n","|          Airline|Airline_indexed|\n","+-----------------+---------------+\n","|Endeavor Air Inc.|           13.0|\n","|Endeavor Air Inc.|           13.0|\n","|Endeavor Air Inc.|           13.0|\n","|Endeavor Air Inc.|           13.0|\n","|Endeavor Air Inc.|           13.0|\n","+-----------------+---------------+\n","only showing top 5 rows\n","\n"]}],"source":["from pyspark.ml.feature import StringIndexer\n","\n","# Encode Airline\n","indexer = StringIndexer(inputCol=\"Airline\", outputCol=\"Airline_indexed\")\n","flight_data = indexer.fit(flight_data).transform(flight_data)\n","\n","# Show the encoded column\n","flight_data.select(\"Airline\", \"Airline_indexed\").show(5)\n"]},{"cell_type":"code","execution_count":9,"id":"3cc68fc2","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Cardinality of Origin: 370\n","Cardinality of Dest: 370\n"]}],"source":["# Count unique values in Origin\n","origin_cardinality = flight_data.select(\"Origin\").distinct().count()\n","print(f\"Cardinality of Origin: {origin_cardinality}\")\n","\n","# Count unique values in Dest\n","dest_cardinality = flight_data.select(\"Dest\").distinct().count()\n","print(f\"Cardinality of Dest: {dest_cardinality}\")\n"]},{"cell_type":"code","execution_count":10,"id":"befc8213","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["+------+----------------+----+--------------+\n","|Origin|Origin_frequency|Dest|Dest_frequency|\n","+------+----------------+----+--------------+\n","|   ABY|             501| ATL|        223860|\n","|   ABY|             501| ATL|        223860|\n","|   ABY|             501| ATL|        223860|\n","|   ABY|             501| ATL|        223860|\n","|   ABY|             501| ATL|        223860|\n","+------+----------------+----+--------------+\n","only showing top 5 rows\n","\n"]}],"source":["from pyspark.sql.functions import col, count, lit\n","\n","# Calculate frequency for Origin\n","origin_freq = flight_data.groupBy(\"Origin\").agg(count(\"Origin\").alias(\"Origin_frequency\"))\n","\n","# Join the frequency back to the main DataFrame\n","flight_data = flight_data.join(origin_freq, on=\"Origin\", how=\"left\")\n","\n","# Calculate frequency for Dest\n","dest_freq = flight_data.groupBy(\"Dest\").agg(count(\"Dest\").alias(\"Dest_frequency\"))\n","\n","# Join the frequency back to the main DataFrame\n","flight_data = flight_data.join(dest_freq, on=\"Dest\", how=\"left\")\n","\n","# Show the results\n","flight_data.select(\"Origin\", \"Origin_frequency\", \"Dest\", \"Dest_frequency\").show(5)\n"]},{"cell_type":"code","execution_count":11,"id":"b5bd20d0","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Dataset with frequency encoding saved to gs://flight-analysis-ms-bucket/trusted/preprocessed_with_frequencies.parquet\n"]}],"source":["# Define the path for the preprocessed data\n","preprocessed_path = \"gs://flight-analysis-ms-bucket/trusted/preprocessed_with_frequencies.parquet\"\n","\n","# Save the dataset\n","flight_data.write.mode(\"overwrite\").parquet(preprocessed_path)\n","\n","print(f\"Dataset with frequency encoding saved to {preprocessed_path}\")\n"]},{"cell_type":"code","execution_count":null,"id":"5a13e21e","metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":5}